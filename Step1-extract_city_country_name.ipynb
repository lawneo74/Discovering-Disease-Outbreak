{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Step 1: Extract city and country names\n","\n","Tasks:\n","- Data exploration\n","- Some are US state rather than city name\n","- Make 'City' an optional search term, as 'City' is sometimes omitted in the headline, e.g., 'Cebu'\n","- Different ways to name the city: 'St. Louis' and 'St Louis' (without period)\n","- Get US states and their cities\n","  \n","Output: \n","df -> dataframe with 3 columns (headlines, city, country)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import libraries\n","import geonamescache\n","from unidecode import unidecode\n","import pandas as pd\n","import re\n","from pathlib import Path\n","import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Read in headlines as list\n","with open(\"./data/headlines.txt\", \"r\") as fh:\n","    all_headlines = fh.readlines()\n","\n","# Replace 'Saints' with 'St.' and strip any trailing space\n","headlines = [headline.replace('Saint', 'St.').strip() for headline in all_headlines]"]},{"cell_type":"markdown","metadata":{},"source":["### Load/Create a dictionary of US states and the cities in each US states - 'US_states_get_cities'\n","\n","Note that it takes a long time to create the dictionary ('US_states_cities.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if Path('US_states_cities.pkl').is_file():\n","    US_state_get_cities = pickle.load(open('US_states_cities.pkl', 'rb'))\n","    gen_US_states_cities = False\n","else:\n","    gen_US_states_cities = True\n","\n","if gen_US_states_cities:\n","    \n","    # for locating US state based on longitude and latitude\n","    from geopy.geocoders import Nominatim\n","\n","    # extract US city names and coordinates\n","    US_cities = [cities[key]['name'] for key in list(cities.keys())\n","                if cities[key]['countrycode'] == 'US']\n","    US_longs = [cities[key]['longitude'] for key in list(cities.keys())\n","                if cities[key]['countrycode'] == 'US']\n","    US_latts = [cities[key]['latitude'] for key in list(cities.keys())\n","                if cities[key]['countrycode'] == 'US']\n","\n","    def get_states(longs, latts):\n","        states = []\n","    \n","        # use a coordinate tool (Nominatim) from the geopy library\n","        geolocator = Nominatim(user_agent='anonymous@gmail.com')\n","        for lon, lat in zip(longs, latts):\n","            try:\\\n","                # get the name of the state\n","                location = geolocator.reverse(str(lat)+', '+str(lon))\n","                state = location.raw['address']['state']\n","            except:\n","                # return empty string\n","                state = ''\n","            states.append(state)\n","        return states\n","\n","    # takes a long time to run the function below.\n","    US_states = get_states(US_longs, US_latts)\n","\n","    US_state_get_cities = {}\n","\n","    for city, state in zip(US_cities, US_states):       \n","        if state != '': \n","            if state in US_state_get_cities.keys():\n","                US_state_get_cities[state].append(city)\n","            elif state not in US_state_get_cities.keys():\n","                US_state_get_cities[state] = [city]\n","\n","    with open('US_states_cities.pkl', 'wb') as fh:\n","        pickle.dump(US_state_get_cities, fh)\n","    \n","print('US_state_get_cities dictionary has been loaded/created: US_state_get_cities')"]},{"cell_type":"markdown","metadata":{},"source":["### Load name of cities and countries from geonamescache"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load a dictionary cities -> 'cities'\n","gc = geonamescache.GeonamesCache()\n","cities = gc.get_cities()\n","countries = gc.get_countries()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Remove '(' and ')' in city name for regex expession; remove 'Beach' from city name\n","city_dict = {}\n","for city in cities.values():\n","    city_name = city['name'].replace('(', '\\(').replace(')','\\)') \n","    \n","    if city_name not in list(city_dict.keys()):\n","        # dictionary key: city name; value: [country name, population size]\n","        city_dict[city_name] = [countries[city['countrycode']]['name'], city['population']]\n","    if unidecode(city_name) != city_name:\n","    # not in list(city_dict.keys()):\n","        city_dict[unidecode(city_name)] = [countries[city['countrycode']]['name'], city['population']]\n","    if city['population'] > city_dict[city_name][1]:\n","        # set 'city' as the one which is most populous\n","        city_dict[city_name] = [countries[city['countrycode']]['name'], city['population']]\n","\n","for city_name, city_val in city_dict.items():\n","    city_dict[city_name] = city_val[0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# remove 'Beach', 'Beaches', 'City' from city names \n","city_beach_dict = {}\n","city2_dict = {}\n","\n","for city_name, city_data in city_dict.items():\n","    if 'Beach' in city_name:\n","        new_city_name = city_name.replace('Beaches', '').strip()\n","        new_city_name = new_city_name.replace('Beach', '').strip()\n","        city_beach_dict[new_city_name] = city_dict[city_name]\n","    if 'City' in city_name:\n","        new_city_name = city_name.replace('City', '').strip()\n","        city2_dict[new_city_name] = city_dict[city_name]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# generate list of city names\n","city_dict.update(city2_dict)\n","city_dict.update(city_beach_dict)\n","city_name = list(city_dict.keys())\n","print('Number of cities in search pattern:', len(city_name))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# compile search patterns using names of city\n","city_regex = re.compile(r'\\b|\\b'.join(city_name))\n","# compile search patterns using names of US states \n","US_states_regex = re.compile(r\"\\b|\\b\".join(list(US_state_get_cities.keys())))"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Search for name of city and country\n","- Name with longest match length is taken as the city name\n","- If name of city is not found using city_regex, then proceed to search for name of US states"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["city_headline = []\n","country_headline = []\n","num_headline_not_found = 0\n","\n","for idx, hl in enumerate(headlines):\n","    possible_city = []\n","    \n","    if city_regex.search(hl):\n","        possible_city = city_regex.findall(hl)\n","    \n","    if len(possible_city) > 0:\n","        city_name2 = max(possible_city, key=len)  # return city name with the longest match \n","        city_headline.append(city_name2)\n","        country_headline.append(city_dict[city_name2])\n","    else:\n","        # search for matches for name of US states\n","        if US_states_regex.search(hl):\n","            # if name of US state is found, then append the list of cities in the US state\n","            list_cities = US_state_get_cities[US_states_regex.search(hl).group()]\n","            city_headline.append(list_cities)\n","            country_headline.append('United States')\n","        else:\n","            # no success for the search in the headline\n","            city_headline.append('')\n","            country_headline.append('')\n","            num_headline_not_found += 1\n","            \n","if num_headline_not_found > 0:\n","    print('\\n')\n","    print('Number of headline(s) with issue locating the city & country:', num_headline_not_found)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Print a sample of headline, city and country\n","n1 = 0   # first entry to display\n","n2 = 5   # last entry to display\n","\n","print('\\n')\n","print('Sample of headline with city & country')\n","\n","for headline, city, country in zip(headlines[n1:n2], city_headline[n1:n2], country_headline[n1:n2]):\n","    print(headline, \" -- City/Country:\", city,'/', country)\n","\n","no_city_idx = [idx for idx, city in enumerate(city_headline) if city == '']\n","\n","print('\\n')\n","print('Sample of headlines (No City and Country)')\n","for i, idx in enumerate(no_city_idx[n1:n2], 1):\n","    print('{i} out of {total}:'.format(i=i, total=num_headline_not_found), headlines[idx])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# export to excel file: headlines_city_country.xlsx\n","df = pd.DataFrame({'headline':headlines, 'city':city_headline, 'country':country_headline})\n","df.to_excel('headlines_city_country.xlsx', index=False)"]}],"metadata":{"interpreter":{"hash":"89bc0f9ad37bcc647357b22c0bbb9fa84f98b4678513817808d7e5fdbc6e24a7"},"kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
